{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Извлечение-признаков\" data-toc-modified-id=\"Извлечение-признаков-0\"><span class=\"toc-item-num\">0&nbsp;&nbsp;</span>Извлечение признаков</a></span></li><li><span><a href=\"#Обучение-сверточной-нейросети-на-картинках\" data-toc-modified-id=\"Обучение-сверточной-нейросети-на-картинках-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Обучение сверточной нейросети на картинках</a></span></li><li><span><a href=\"#Добавление-столбца-с-предсказаниями-нейросети-к-данным-с-голосом\" data-toc-modified-id=\"Добавление-столбца-с-предсказаниями-нейросети-к-данным-с-голосом-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Добавление столбца с предсказаниями нейросети к данным с голосом</a></span></li><li><span><a href=\"#На-получившемся-датасете-обучаем-RandomForestClassifier\" data-toc-modified-id=\"На-получившемся-датасете-обучаем-RandomForestClassifier-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>На получившемся датасете обучаем RandomForestClassifier</a></span></li><li><span><a href=\"#Готовим-submit-data\" data-toc-modified-id=\"Готовим-submit-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Готовим submit data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:48:30.034353Z",
     "start_time": "2019-11-20T12:48:30.029080Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждой арабской цифры имеется скан записи на бумаге (`./data/train/image`) и запись произношения на английском языке разными дикторами (`./data/train/voice`)\n",
    "\n",
    "Требуется построить модель для классификации цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:48:33.017318Z",
     "start_time": "2019-11-20T12:48:33.010184Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "\n",
    "IMAGE_TRAIN_PATH = \"./data/train/image\"\n",
    "VOICE_TRAIN_PATH = \"./data/train/voice\"\n",
    "IMAGE_TEST_PATH = \"./data/test/image/\"\n",
    "VOICE_TEST_PATH = \"./data/test/voice/\"\n",
    "\n",
    "def read_image(path):\n",
    "    return PIL.Image.open(path).convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:48:56.717286Z",
     "start_time": "2019-11-20T12:48:56.029304Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:48:59.329119Z",
     "start_time": "2019-11-20T12:48:59.326056Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_wav(path):\n",
    "    return librosa.load(path, sr=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:49:14.449839Z",
     "start_time": "2019-11-20T12:49:14.236754Z"
    }
   },
   "outputs": [],
   "source": [
    "durations = []\n",
    "\n",
    "for name in os.listdir(VOICE_TRAIN_PATH):\n",
    "    path = os.path.join(VOICE_TRAIN_PATH, name)\n",
    "    signal, sr = load_wav(path)\n",
    "    duration = signal.size / float(sr)\n",
    "    durations.append(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:49:15.646173Z",
     "start_time": "2019-11-20T12:49:15.038013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(durations, bins=20)\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:49:18.150233Z",
     "start_time": "2019-11-20T12:49:17.722971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_127.png\n",
      "1_20.png\n"
     ]
    }
   ],
   "source": [
    "sum_intensity = np.zeros((28, 28), dtype=np.float32)\n",
    "\n",
    "zero_element_counts = []\n",
    "\n",
    "for name in os.listdir(IMAGE_TRAIN_PATH):\n",
    "    path = os.path.join(IMAGE_TRAIN_PATH, name)\n",
    "    img = read_image(path)\n",
    "    np_img = np.array(img)\n",
    "    zero_count = (np_img < 1.0).astype(int).sum()\n",
    "    zero_element_counts.append(zero_count)\n",
    "    sum_intensity += np_img\n",
    "    if zero_count > 735 or zero_count < 492:\n",
    "        print(name)\n",
    "    '''\n",
    "    ipd.clear_output(wait=True)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(sum_intensity, cmap=\"plasma\")\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:49:18.793764Z",
     "start_time": "2019-11-20T12:49:18.570228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD6CAYAAABamQdMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXqklEQVR4nO3dX2xT9/3/8Zf/BLaQ5Y/jBBT+iKYJFyBaQM5KYSUZeBVat47vNEUqpRNQhsAMNEoraFVNlRjCUgdJoURoa5du9KLdRZOu/a3r5GUEaVE1Q8LKoKOloxVVKMZxmiX8T3J+FxUWlNDEJ7ZjPn4+rvD548/7wzm8OP74+HMclmVZAgAYxTnWBQAAko9wBwADEe4AYCDCHQAMRLgDgIEIdwAwkHu4DRoaGtTe3q6CggLt2rUrvvydd97Ru+++K6fTqXnz5mnFihWSpKamJrW0tMjpdGrVqlWaM2dO6qoHAAxp2HCvqanR0qVLtW/fvviyf//73zp8+LCef/555eTkqKenR5L02Wefqa2tTbt371Z3d7e2b9+uF154QU4nHxAAIJ2GDfeZM2cqEonctOyvf/2rfvSjHyknJ0eSVFBQIEkKh8NasGCBcnJyVFpaqkmTJunUqVOaMWPGsIV0dnbaqT9hXq9X0Wg0LW1lEvqdXeh3digrK7vtumHDfShnz57Vf/7zH7322mvKycnRY489poqKCsViMVVWVsa383g8isVidpoAAIyCrXAfHBxUX1+fduzYoY8//lh1dXV68cUXE3qPUCikUCgkSQoGg/J6vXZKSZjb7U5bW5mEfmcX+g1b4e7xePTtb39bDodDFRUVcjqd6u3tlcfjUVdXV3y7WCwmj8cz5Hv4/X75/f7463R9lMq2j23X0e/sQr+zw9cNy9j6prOqqkrHjx+X9OVYeX9/v771rW/J5/Opra1N165dUyQS0dmzZ1VRUWGvagCAbcNeudfX1+vEiRPq7e3VunXrVFtbq8WLF6uhoUFbtmyR2+3Whg0b5HA4NHXqVN1///164okn5HQ69fjjj3OnDACMAUemTPnL3TKpRb+zC/3ODkkflgEAZDbCHQAMRLgDgIFs3QoJIPUGfvZwQtu7fvunFFWCOxFX7gBgIMIdAAxEuAOAgQh3ADAQ4Q4ABuJuGcAQN95dc24E23N3jdm4cgcAAxHuAGAgwh0ADES4A4CBCHcAMBDhDgAGItwBwECEOwAYaNhwb2ho0Jo1a7Rly5Zb1r311luqra3V//73P0mSZVn63e9+p40bN+rJJ5/Uf//73+RXDAAY1rDhXlNTo2eeeeaW5dFoVO+//768Xm98WUdHhz7//HPt2bNHa9eu1UsvvZTcagEAIzLs9AMzZ85UJBK5Zfnvf/97Pfroo3r++efjyw4fPqxFixbJ4XBoxowZunDhgrq7u1VUVJTcqoEMwMM0kMlsjbmHw2F5PB5Nnz79puWxWOymK/ni4mLFYrFRFQgASFzCE4dduXJFTU1NevbZZ0fVcCgUUigUkiQFg8Gb/lNIJbfbnba2Mgn9Tr6RTM51o0TrSPT9E2Xi+ZCt5/lQEg73c+fOKRKJ6KmnnpIkdXV1aevWrdq5c6c8Ho+i0Wh8266uLnk8niHfx+/3y+/3x1/fuF8qeb3etLWVSej32MuUOq7LtHqSIZOOdzqUlZXddl3C4T5t2rSbvijdsGGDdu7cqfz8fPl8Pv3lL3/RwoUL9dFHHyk3N5fxdgAYA8OGe319vU6cOKHe3l6tW7dOtbW1Wrx48ZDbzp07V+3t7dq0aZPGjRunQCCQ9IIBAMMbNtx/8YtffO36ffv2xf/scDi0Zs2a0VcFABgVfqEKAAYi3AHAQIQ7ABiIcAcAAxHuAGAgwh0ADES4A4CBCHcAMBDhDgAGItwBwECEOwAYiHAHAAMR7gBgIMIdAAxEuAOAgQh3ADAQ4Q4ABiLcAcBAwz5mr6GhQe3t7SooKNCuXbskSQcOHNCRI0fkdrs1ceJEBQIBTZgwQZLU1NSklpYWOZ1OrVq1SnPmzEltDwAAtxg23GtqarR06dKbnpV6zz33aPny5XK5XHr11VfV1NSkFStW6LPPPlNbW5t2796t7u5ubd++XS+88IKcTj4gIPMN/OzhsS4BSJphU3fmzJnKy8u7adm9994rl8slSZoxY4ZisZgkKRwOa8GCBcrJyVFpaakmTZqkU6dOpaBsAMDXGfbKfTgtLS1asGCBJCkWi6mysjK+zuPxxIP/q0KhkEKhkCQpGAzK6/WOtpQRcbvdaWsrk9Dv4Z1LcS2Z9snAxPMhW8/zoYwq3N944w25XC498MADCe/r9/vl9/vjr6PR6GhKGTGv15u2tjIJ/cZXmfj3km3Hu6ys7LbrbA+GHzx4UEeOHNGmTZvkcDgkfXml3tXVFd8mFovJ4/HYbQIAYJOtcD969KjefPNNbd26VePHj48v9/l8amtr07Vr1xSJRHT27FlVVFQkrVgAwMgMOyxTX1+vEydOqLe3V+vWrVNtba2amprU39+v7du3S5IqKyu1du1aTZ06Vffff7+eeOIJOZ1OPf7449wpAwBjwGFZljXWRUhSZ2dnWtrJtjG56+j38DLtC89Uc/32T2NdQtJl23mekjF3AEDmItwBwECEOwAYiHAHAAMR7gBgIMIdAAxEuAOAgQh3ADAQ4Q4ABiLcAcBAhDsAGIhwBwADEe4AYCDCHQAMRLgDgIEIdwAwEOEOAAYa9jF7wJ3o+lOVzo1xHZnMzpOnTHx6k6mGDfeGhga1t7eroKBAu3btkiT19fWprq5O58+fV0lJiTZv3qy8vDxZlqXGxkZ1dHRo/PjxCgQCKi8vT3knAAA3G3ZYpqamRs8888xNy5qbmzV79mzt2bNHs2fPVnNzsySpo6NDn3/+ufbs2aO1a9fqpZdeSk3VAICvNWy4z5w5U3l5eTctC4fDqq6uliRVV1crHA5Lkg4fPqxFixbJ4XBoxowZunDhgrq7u1NQNgDg69gac+/p6VFRUZEkqbCwUD09PZKkWCwmr9cb3664uFixWCy+7Y1CoZBCoZAkKRgM3rRfKrnd7rS1lUmyrd+MtadGpp9D2Xaef51Rf6HqcDjkcDgS3s/v98vv98dfR6PR0ZYyIl6vN21tZZJs7TeSK9PPoWw7z8vKym67ztatkAUFBfHhlu7ubuXn50uSPB7PTX+xXV1d8ng8dpoAAIyCrXD3+XxqbW2VJLW2tqqqqiq+/NChQ7IsSx9++KFyc3OHHJIBAKTWsMMy9fX1OnHihHp7e7Vu3TrV1tZq2bJlqqurU0tLS/xWSEmaO3eu2tvbtWnTJo0bN06BQCDlHQAA3MphWZY11kVIUmdnZ1raybYxueuyrd92fqCD4WX6j5iy7TxP+pg7ACCzMf0A7ghciQOJ4codAAxEuAOAgQh3ADAQ4Q4ABiLcAcBAhDsAGIhwBwADEe4AYCDCHQAMRLgDgIEIdwAwEOEOAAYi3AHAQIQ7ABiIcAcAAxHuAGCgUT2s4+2331ZLS4scDoemTp2qQCCgL774QvX19ert7VV5ebk2btwot5tnggBAOtlO3VgspnfeeUd1dXUaN26cdu/erba2NrW3t+uhhx7SwoUL9Zvf/EYtLS168MEHk1kzgDGS6BOxMv2ZqyYb1bDM4OCgrl69qoGBAV29elWFhYU6fvy45s+fL0mqqalROBxOSqEAgJGzfeXu8Xj0wx/+UOvXr9e4ceN07733qry8XLm5uXK5XPFtYrHYkPuHQiGFQiFJUjAYlNfrtVtKQtxud9rayiR3er/PjXUBsCXd59ydfp4nk+1w7+vrUzgc1r59+5Sbm6vdu3fr6NGjI97f7/fL7/fHX0ejUbulJMTr9aatrUySrf3G2Er3OZdt53lZWdlt19kO92PHjqm0tFT5+fmSpPvuu08nT57UxYsXNTAwIJfLpVgsJo/HY7cJAIBNtsfcvV6vPvroI125ckWWZenYsWOaMmWKZs2apffee0+SdPDgQfl8vqQVCwAYGdtX7pWVlZo/f762bt0ql8ul6dOny+/3a968eaqvr9drr72mu+66S4sXL05mvQCAEXBYlmWNdRGS1NnZmZZ2sm1M7ro7vd+J3oKHzJDuWyHv9PM8UV835s4vVAHAQIQ7ABiIcAcAAxHuAGAgZvTCmOALUiC1uHIHAAMR7gBgIMIdAAxEuAOAgQh3ADAQ4Q4ABiLcAcBAhDsAGIhwBwADEe4AYCDCHQAMRLgDgIEIdwAw0Khmhbxw4YL279+vM2fOyOFwaP369SorK1NdXZ3Onz+vkpISbd68WXl5ecmqFwAwAqMK98bGRs2ZM0dbtmxRf3+/rly5oqamJs2ePVvLli1Tc3OzmpubtWLFimTVCwAYAdvhfvHiRX3wwQfasGHDl2/kdsvtdiscDuu5556TJFVXV+u5554j3IEslei8/el+oLbJbId7JBJRfn6+Ghoa9Omnn6q8vFwrV65UT0+PioqKJEmFhYXq6ekZcv9QKKRQKCRJCgaD8nq9dktJiNvtTltbmSTT+n1urAtARhrtOZpp5/lYsh3uAwMDOn36tFavXq3Kyko1Njaqubn5pm0cDoccDseQ+/v9fvn9/vjraDRqt5SEeL3etLWVSbK137izjPYczbbzvKys7LbrbN8tU1xcrOLiYlVWVkqS5s+fr9OnT6ugoEDd3d2SpO7ubuXn59ttAgBgk+1wLywsVHFxsTo7OyVJx44d05QpU+Tz+dTa2ipJam1tVVVVVXIqBQCM2Kjullm9erX27Nmj/v5+lZaWKhAIyLIs1dXVqaWlJX4rJMzHA6+BzDKqcJ8+fbqCweAty3/5y1+O5m0BAKPEL1QBwECEOwAYiHAHAAMR7gBgIMIdAAxEuAOAgQh3ADAQ4Q4ABiLcAcBAo/qFKgCMpa9OezHcVNLZNF88V+4AYCDCHQAMRLgDgIEIdwAwEOEOAAYi3AHAQIQ7ABiIcAcAA436R0yDg4Patm2bPB6Ptm3bpkgkovr6evX29qq8vFwbN26U281vpQAgnUZ95f7nP/9ZkydPjr9+9dVX9dBDD2nv3r2aMGGCWlpaRtsEACBBowr3rq4utbe3a8mSJZIky7J0/PhxzZ8/X5JUU1OjcDg8+ioBAAkZ1XjJK6+8ohUrVujSpUuSpN7eXuXm5srlckmSPB6PYrHYkPuGQiGFQiFJUjAYlNfrHU0pI+Z2u9PWViZJdb+Hm9MDGIlEz9FEz7ts+rdvO9yPHDmigoIClZeX6/jx4wnv7/f75ff746+j0ajdUhLi9XrT1lYmydZ+485y7v8WpPT9Tfs3UFZWdtt1tsP95MmTOnz4sDo6OnT16lVdunRJr7zyii5evKiBgQG5XC7FYjF5PB67TQAAbLId7suXL9fy5cslScePH9dbb72lTZs2affu3Xrvvfe0cOFCHTx4UD6fL2nFAgBGJun3uT/66KN6++23tXHjRvX19Wnx4sXJbgIAMIyk3IA+a9YszZo1S5I0ceJE7dy5MxlvCwCwiV+oAoCBCHcAMBDhDgAGItwBwECEOwAYiHAHAAMR7gBgIMIdAAxEuAOAgQh3ADAQz7/LAgM/ezjhea9dv/1TSmoBkB6EO4CsMfCzhxPa/k6+yGFYBgAMRLgDgIEYlsGQEv34CiCzcOUOAAYi3AHAQLaHZaLRqPbt26cvvvhCDodDfr9f3//+99XX16e6ujqdP39eJSUl2rx5s/Ly8pJZMwCkhZ3hyUy5w8Z2uLtcLj322GMqLy/XpUuXtG3bNt1zzz06ePCgZs+erWXLlqm5uVnNzc1asWJFMmsGAAzD9rBMUVGRysvLJUnf/OY3NXnyZMViMYXDYVVXV0uSqqurFQ6Hk1MpAGDEkjLmHolEdPr0aVVUVKinp0dFRUWSpMLCQvX09CSjCQBAAkZ9K+Tly5e1a9curVy5Urm5uTetczgccjgcQ+4XCoUUCoUkScFgUF6vd7SljIjb7U5bW5ki0akHANiXKfkyqnDv7+/Xrl279MADD+i+++6TJBUUFKi7u1tFRUXq7u5Wfn7+kPv6/X75/f7462g0OppSRszr9aatLQDZJ535UlZWdtt1todlLMvS/v37NXnyZP3gBz+IL/f5fGptbZUktba2qqqqym4TAACbbF+5nzx5UocOHdK0adP01FNPSZIeeeQRLVu2THV1dWppaYnfCgkASC+HZVnWWBchSZ2dnWlpJxuHZZhKAEifdN7nnpJhGQBA5iLcAcBAzAqZAbLpAQIA0oNwvwMxhg5gOAzLAICBCHcAMBDhDgAGItwBwEB8oZoCfOEJYKxx5Q4ABiLcAcBAhDsAGIhwBwADEe4AYCDulgGAJMqUuaK4cgcAAxHuAGAgwh0ADJSyMfejR4+qsbFRg4ODWrJkiZYtW5aqpgAAX5GScB8cHNTLL7+sZ599VsXFxXr66afl8/k0ZcqUVDSXckwnAOBOk5JwP3XqlCZNmqSJEydKkhYsWKBwOJyScE80eM8lvQIAyDwpGXOPxWIqLi6Ovy4uLlYsFktFUwCAIYzZfe6hUEihUEiSFAwGVVZWZu+N/t/hJFYFAGZIyZW7x+NRV1dX/HVXV5c8Hs9N2/j9fgWDQQWDwVSUcFvbtm1La3uZgn5nF/qNlIT73XffrbNnzyoSiai/v19tbW3y+XypaAoAMISUDMu4XC6tXr1aO3bs0ODgoL773e9q6tSpqWgKADCElI25z5s3T/PmzUvV29vm9/vHuoQxQb+zC/2Gw7Isa6yLAAAkF9MPAICBjJvyd8OGDfrGN74hp9Mpl8ulYDCovr4+1dXV6fz58yopKdHmzZuVl5cny7LU2Niojo4OjR8/XoFAQOXl5WPdBVuG6vcf//hH/e1vf1N+fr4k6ZFHHokPlTU1NamlpUVOp1OrVq3SnDlzxrJ82y5cuKD9+/frzJkzcjgcWr9+vcrKyow/3kP1++jRo0Yf787OTtXV1cVfRyIR1dbWqrq62vjjbYtlmEAgYPX09Ny07MCBA1ZTU5NlWZbV1NRkHThwwLIsyzpy5Ii1Y8cOa3Bw0Dp58qT19NNPp73eZBmq36+//rr15ptv3rLtmTNnrCeffNK6evWqde7cOevnP/+5NTAwkK5Sk2rv3r1WKBSyLMuyrl27ZvX19WXF8R6q39lwvK8bGBiw1qxZY0Uikaw43nZkxbBMOBxWdXW1JKm6ulrhcFiSdPjwYS1atEgOh0MzZszQhQsX1N3dPZalpkU4HNaCBQuUk5Oj0tJSTZo0SadOnRrrshJ28eJFffDBB1q8eLEkye12a8KECcYf79v1+3ZMOd43OnbsmCZNmqSSkhLjj7ddxg3LSNKOHTskSd/73vfk9/vV09OjoqIiSVJhYaF6enokfTlNgtfrje93fZqE69veab7ab0l69913dejQIZWXl+unP/2p8vLyFIvFVFlZGd/P4/HckdNDRCIR5efnq6GhQZ9++qnKy8u1cuVK44/37fotmX28b/SPf/xDCxculCTjj7ddxoX79u3b5fF41NPTo1/96le3TGvgcDjkcDjGqLrUGarfDz74oH7yk59Ikl5//XX94Q9/UCAQGONKk2dgYECnT5/W6tWrVVlZqcbGRjU3N9+0jYnH+3b9Xrp0qdHH+7r+/n4dOXJEy5cvv2WdicfbLuOGZa5Pc1BQUKCqqiqdOnVKBQUF8Y9j3d3d8S+cPB6PotFofN+hpkm4UwzV78LCQjmdTjmdTi1ZskQff/xxfNsbp4eIxWJ3ZL+Li4tVXFwcvyqdP3++Tp8+bfzxvl2/TT/e13V0dOiuu+5SYWGhJBl/vO0yKtwvX76sS5cuxf/8/vvva9q0afL5fGptbZUktba2qqqqSpLk8/l06NAhWZalDz/8ULm5uXfkR7bb9fvG8cV//vOf8V8J+3w+tbW16dq1a4pEIjp79qwqKirGpPbRKCwsVHFxsTo7OyV9OQ47ZcoU44/37fpt+vG+7sYhGUnGH2+7jPoR07lz5/TrX/9a0pcfXb/zne/oxz/+sXp7e1VXV6doNHrLrVIvv/yy/vWvf2ncuHEKBAK6++67x7gXibtdv/fu3atPPvlEDodDJSUlWrt2bfzkfuONN/T3v/9dTqdTK1eu1Ny5c8eyC7Z98skn2r9/v/r7+1VaWqpAICDLsow+3tLQ/W5sbDT+eF++fFmBQEAvvviicnNzJcn4f992GRXuAIAvGTUsAwD4EuEOAAYi3AHAQIQ7ABiIcAcAAxHuAGAgwh0ADES4A4CB/j88eJD5tts+ugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(zero_element_counts, bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлечение признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:49:26.359567Z",
     "start_time": "2019-11-20T12:49:26.192699Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ann/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:49:28.538737Z",
     "start_time": "2019-11-20T12:49:28.526451Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_image_features(image_folder):\n",
    "    image_vectors = []\n",
    "    indices = []\n",
    "    for image_name in os.listdir(image_folder):\n",
    "        index = os.path.splitext(image_name)[0]\n",
    "        indices.append(index)\n",
    "        image = read_image(os.path.join(image_folder, image_name))\n",
    "        image_vector = np.array(image).reshape(-1)\n",
    "        image_vectors.append(image_vector)\n",
    "    return pd.DataFrame({\n",
    "        'index': indices,\n",
    "        'image_vector': image_vectors,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:49:53.618948Z",
     "start_time": "2019-11-20T12:49:52.439504Z"
    }
   },
   "outputs": [],
   "source": [
    "image_features_tr = extract_image_features(IMAGE_TRAIN_PATH)\n",
    "image_features_te = extract_image_features(IMAGE_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:50:05.990865Z",
     "start_time": "2019-11-20T12:50:05.977173Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_voice_features(voice_folder, numcep=100, hop_length=256):\n",
    "    voice_vectors = []\n",
    "    indices = []\n",
    "    for record_name in os.listdir(voice_folder):\n",
    "        index = os.path.splitext(record_name)[0]\n",
    "        indices.append(index)\n",
    "        signal, sr = load_wav(\n",
    "            os.path.join(voice_folder, record_name)\n",
    "        )\n",
    "        mfcc_features = librosa.feature.mfcc(\n",
    "            signal, sr=sr, n_mfcc=numcep, hop_length=hop_length\n",
    "        )\n",
    "        voice_vector = mfcc_features.mean(axis=1)\n",
    "        voice_vectors.append(voice_vector)\n",
    "    return pd.DataFrame({\n",
    "        'index': indices,\n",
    "        'voice_vector': voice_vectors,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:50:35.207186Z",
     "start_time": "2019-11-20T12:50:25.120350Z"
    }
   },
   "outputs": [],
   "source": [
    "voice_features_tr = extract_voice_features(VOICE_TRAIN_PATH)\n",
    "voice_features_te = extract_voice_features(VOICE_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:51:05.359212Z",
     "start_time": "2019-11-20T12:51:05.341585Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_tr = image_features_tr.merge(voice_features_tr, on='index')\n",
    "dataset_te = image_features_te.merge(voice_features_te, on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:51:10.418019Z",
     "start_time": "2019-11-20T12:51:10.411026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:51:33.627837Z",
     "start_time": "2019-11-20T12:51:33.617133Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_tr[\"target\"] = dataset_tr[\"index\"].apply(lambda x: int(x[0]))\n",
    "dataset_te[\"target\"] = dataset_te[\"index\"].apply(lambda x: int(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение сверточной нейросети на картинках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:52:21.703905Z",
     "start_time": "2019-11-20T12:52:21.677780Z"
    }
   },
   "outputs": [],
   "source": [
    "X_trainimg = np.vstack(dataset_tr[\"image_vector\"].values/255)\n",
    "y_trainimg = dataset_tr[\"target\"]\n",
    "X_testimg = np.vstack(dataset_te[\"image_vector\"].values/255)\n",
    "y_testimg = dataset_te[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:52:26.546118Z",
     "start_time": "2019-11-20T12:52:26.529838Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ann/.pyenv/versions/3.6.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1500, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_trainimg = encoder.fit_transform(np.array(y_trainimg).reshape(-1, 1))\n",
    "y_trainimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:52:29.625231Z",
     "start_time": "2019-11-20T12:52:29.614566Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ann/.pyenv/versions/3.6.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_testimg = encoder.fit_transform(np.array(y_testimg).reshape(-1, 1))\n",
    "y_testimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:52:32.904687Z",
     "start_time": "2019-11-20T12:52:32.898039Z"
    }
   },
   "outputs": [],
   "source": [
    "X_trainimg = X_trainimg.reshape(-1, 28, 28, 1)\n",
    "X_testimg = X_testimg.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:52:33.942455Z",
     "start_time": "2019-11-20T12:52:33.929858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 28, 28, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:52:38.409248Z",
     "start_time": "2019-11-20T12:52:37.616849Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ann/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ann/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ann/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ann/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ann/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ann/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:52:40.762322Z",
     "start_time": "2019-11-20T12:52:40.741225Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:52:43.525358Z",
     "start_time": "2019-11-20T12:52:43.406668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ann/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:52:46.678056Z",
     "start_time": "2019-11-20T12:52:46.618528Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:54:41.828014Z",
     "start_time": "2019-11-20T12:53:59.792672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2540 - accuracy: 0.9253 - val_loss: 8.6333 - val_accuracy: 0.1100\n",
      "Epoch 2/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1767 - accuracy: 0.9487 - val_loss: 10.1987 - val_accuracy: 0.1060\n",
      "Epoch 3/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1396 - accuracy: 0.9500 - val_loss: 10.4624 - val_accuracy: 0.1080\n",
      "Epoch 4/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1211 - accuracy: 0.9607 - val_loss: 10.5358 - val_accuracy: 0.1120\n",
      "Epoch 5/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0946 - accuracy: 0.9667 - val_loss: 10.9879 - val_accuracy: 0.1120\n",
      "Epoch 6/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0834 - accuracy: 0.9747 - val_loss: 11.0132 - val_accuracy: 0.1120\n",
      "Epoch 7/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0627 - accuracy: 0.9793 - val_loss: 11.7191 - val_accuracy: 0.1100\n",
      "Epoch 8/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0584 - accuracy: 0.9813 - val_loss: 11.7790 - val_accuracy: 0.1140\n",
      "Epoch 9/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0579 - accuracy: 0.9833 - val_loss: 12.1847 - val_accuracy: 0.1080\n",
      "Epoch 10/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0436 - accuracy: 0.9860 - val_loss: 12.2826 - val_accuracy: 0.1120\n",
      "Epoch 11/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0370 - accuracy: 0.9867 - val_loss: 12.4923 - val_accuracy: 0.1100\n",
      "Epoch 12/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0276 - accuracy: 0.9920 - val_loss: 12.6400 - val_accuracy: 0.1120\n",
      "Epoch 13/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 12.6002 - val_accuracy: 0.1120\n",
      "Epoch 14/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0297 - accuracy: 0.9913 - val_loss: 12.9283 - val_accuracy: 0.1060\n",
      "Epoch 15/15\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0300 - accuracy: 0.9893 - val_loss: 12.8894 - val_accuracy: 0.1100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fcc9417aeb8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_trainimg, y_trainimg,\n",
    "          batch_size=30,\n",
    "          epochs=15,\n",
    "          verbose=1,\n",
    "          validation_data=(X_testimg, y_testimg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:54:52.188549Z",
     "start_time": "2019-11-20T12:54:51.979834Z"
    }
   },
   "outputs": [],
   "source": [
    "pred=model.predict(X_testimg).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:55:03.088290Z",
     "start_time": "2019-11-20T12:55:03.081853Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_voice_features(voice_folder, numcep=100, hop_length=256):\n",
    "    voice_vectors = []\n",
    "    indices = []\n",
    "    for record_name in os.listdir(voice_folder):\n",
    "        index = os.path.splitext(record_name)[0]\n",
    "        indices.append(index)\n",
    "        signal, sr = load_wav(\n",
    "            os.path.join(voice_folder, record_name)\n",
    "        )\n",
    "        mfcc_features = librosa.feature.mfcc(\n",
    "            signal, sr=sr, n_mfcc=numcep, hop_length=hop_length\n",
    "        )\n",
    "        voice_vector = mfcc_features.mean(axis=1)\n",
    "        voice_vectors.append(voice_vector)\n",
    "    return pd.DataFrame({\n",
    "        'index': indices,\n",
    "        'voice_vector': voice_vectors,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:55:30.340869Z",
     "start_time": "2019-11-20T12:55:30.298504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_vector</th>\n",
       "      <th>voice_vector</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-454.70526, 54.62366, 11.140218, 22.32652, -8...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-181.37611, 41.81173, 23.814613, 4.1566625, -...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>361</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-220.0484, 46.701973, 9.449443, 9.587729, -4....</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-227.78001, 158.38046, -45.224712, -39.631256...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>428</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-195.73018, 93.947205, 9.354431, -37.064545, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>411</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-138.72755, 80.69298, -26.852268, -38.903732,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>175</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-183.9127, 93.89262, 20.996738, -58.348854, -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>456</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-171.60304, 89.863045, -27.909735, -7.473554,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>476</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-189.14445, 49.78231, -8.477941, -0.78951895,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>187</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-381.80698, 108.32417, -16.850464, -28.252697...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                       image_vector  \\\n",
       "0     285  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     212  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     361  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     347  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     428  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "..    ...                                                ...   \n",
       "495   411  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "496   175  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "497   456  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "498   476  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "499   187  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          voice_vector  target  \n",
       "0    [-454.70526, 54.62366, 11.140218, 22.32652, -8...       2  \n",
       "1    [-181.37611, 41.81173, 23.814613, 4.1566625, -...       2  \n",
       "2    [-220.0484, 46.701973, 9.449443, 9.587729, -4....       3  \n",
       "3    [-227.78001, 158.38046, -45.224712, -39.631256...       3  \n",
       "4    [-195.73018, 93.947205, 9.354431, -37.064545, ...       4  \n",
       "..                                                 ...     ...  \n",
       "495  [-138.72755, 80.69298, -26.852268, -38.903732,...       4  \n",
       "496  [-183.9127, 93.89262, 20.996738, -58.348854, -...       1  \n",
       "497  [-171.60304, 89.863045, -27.909735, -7.473554,...       4  \n",
       "498  [-189.14445, 49.78231, -8.477941, -0.78951895,...       4  \n",
       "499  [-381.80698, 108.32417, -16.850464, -28.252697...       1  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление столбца с предсказаниями нейросети к данным с голосом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:56:38.256683Z",
     "start_time": "2019-11-20T12:56:37.574841Z"
    }
   },
   "outputs": [],
   "source": [
    "X_trainv = np.hstack((np.vstack(dataset_tr[\"voice_vector\"].values),np.vstack(model.predict(X_trainimg).argmax(axis=1))))\n",
    "y_trainv = dataset_tr[\"target\"]\n",
    "X_testv = np.hstack((np.vstack(dataset_te[\"voice_vector\"].values),np.vstack(model.predict(X_testimg).argmax(axis=1))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### На получившемся датасете обучаем RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:57:00.268135Z",
     "start_time": "2019-11-20T12:56:58.950378Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=150, min_samples_split=2, min_samples_leaf=5).fit(X_trainv, y_trainv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:57:08.062825Z",
     "start_time": "2019-11-20T12:57:07.995624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993333333333333"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_trainv, y_trainv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Готовим submit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:58:50.748120Z",
     "start_time": "2019-11-20T12:58:48.649000Z"
    }
   },
   "outputs": [],
   "source": [
    "submit_image_features = extract_image_features(IMAGE_TEST_PATH)\n",
    "submit_voice_features = extract_voice_features(VOICE_TEST_PATH)\n",
    "submit_dataset = submit_image_features.merge(\n",
    "    submit_voice_features, \n",
    "    on=\"index\"\n",
    ")\n",
    "submit_dataset[\"index\"] = submit_dataset[\"index\"].apply(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T19:54:50.635729Z",
     "start_time": "2019-11-18T19:54:50.630321Z"
    }
   },
   "source": [
    "make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:58:54.441818Z",
     "start_time": "2019-11-20T12:58:54.413811Z"
    }
   },
   "outputs": [],
   "source": [
    "submit_dataset[\"target\"] = clf.predict(X_testv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T12:59:11.015919Z",
     "start_time": "2019-11-20T12:59:11.002150Z"
    }
   },
   "outputs": [],
   "source": [
    "submit_dataset[[\"index\", \"target\"]] \\\n",
    "    .sort_values(\"index\") \\\n",
    "    .to_csv(\"random_submission1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {
    "height": "346px",
    "width": "417px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "386px",
    "left": "261px",
    "top": "133px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
